Hyperparameters:
batch_size = 167
nb_epoch = 1000
learning_rate = 0.0005
loss_fun = mse
shuffle_flag = True
optimizer = adam



Layers:
linear(3, 200)
relu
linear(200, 200)
relu
linear(200, 3)
Training Loss: 3.906183337676339e-06
Validation Loss: 4.778649326908635e-06
Test Loss: 4.784208158525871e-06
